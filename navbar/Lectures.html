<section id="main_content" class="inner" style="height:100%;display:block;">
    <style>
        style_noborder{
        border-width: 0px;
        }
        .style_white {
        border-style: solid;
        border-width: 1px;
        background-color: #ffffff;
             }
     .style_emphasize {
        border-style: solid;
        border-width: 1px;
        background-color:#F4F2D8;;
             }
     </style>
    <table style="width: 100%" class="style_noborder ">
        <tr>
            <td class="style_emphasize " colspan="3"> 
                <ul style="color: #cc0000"> 
                        <li> Textbooks: None required, but I find the following helpful
                        <ul>
                            <li>'Python for Data Analysis' by Wes McKinney - mostly for pandas help</li>
                            <li>'Machine Learning with Python Cookbook' by Chris Albon - short data/ml recipes</li>
                            <li>'Python Machine Learning' by Sebastian Raschka - Excellent machine learning introduction</li>
                        </ul>
                    </li>
                  </ul>
            </td>
    
        </tr>
         <tr>
            <td class="style_white "><em><strong>Week</strong></em></td>
            <td class="style_white "><em><strong>Lectures/Readings</strong></em></td>
            <td class="style_white "><em><strong>Examples</strong></em></td>
        </tr>
        <tr>
            <td class="style_white "><em>1</em></td>
            <td class="style_white ">
                <!--excellent notebooks, see sebastian raschke github https://github.com/rasbt/stat451-machine-learning-fs21.git 
                   need a better treatment of error metrics for regression (R^2, mean absolute error (MAE) etc)
                where to get datasets https://www.openml.org/home
                                    https://archive-beta.ics.uci.edu/ml/datasets?f%5Bcharacteristics%5D=tabular&f%5Barea%5D%5B0%5D=social-sciences&f%5Btask%5D=regression&p%5Boffset%5D=0&p%5Blimit%5D=10&p%5BorderBy%5D=NumHits&p%5Border%5D=desc&p%5BStatus%5D=APPROVED-->

                <!--<ul><strong>Tools to help you keep track of research</strong>
                    <li>A note taking App (like evernote)</li>
                    <li>A web highlighter, to highlight and web pages (like Weava)</li>
                    <li><a href="arxiv.org">ArXiv</a> - pre print of technical papers, go here to read original research</li>
                    <li>A place to store documents you are reading (like <a href="https://www.mendeley.com">Mendeley</a>)</li>
                
                    <li>Jupyter extensions for Jupyter notebooks (these can be finniky)</li>
                </ul>-->
                <strong>Lectures</strong><BR>
                <strong><a href="https://github.com/CNUClasses/DATA301/blob/master/content/lectures/week1/1_Introduction.pdf"> Syllabus and Course Introduction</a></strong><br>
                <strong><a href="https://github.com/CNUClasses/DATA301/blob/master/content/lectures/week1/2_workflow.pdf"> A general approach to a Data Science question</a></strong> there are lots of variations<br>
                <strong><a href="https://github.com/CNUClasses/DATA301/blob/master/content/lectures/week1/3_tools.pdf"> Anaconda, Virtual Environments, Jupyter Lab, Optional record keeping tools</a></strong> Tools for this class and some optional tools to help you keep track of information<br>
                <strong><a href="https://github.com/CNUClasses/DATA301/blob/master/content/lectures/week1/3_setup_data301_python_environment_with_notebook_templates.txt"> List of commands to set up a virtual environment, switch to it and then invoke jupyter lab</a></strong>  Plus a bit on configuring notebook templates<br><br>
                <strong><a href="https://github.com/CNUClasses/DATA301/blob/master/content/hotkeys/hotkeys.txt" style="color: #00cc00"> Jupyter Lab shortcuts Keys</a></strong><br>
                Jupyter notebooks are a great way to prototype; you can write a bit of code, test it and change it without having to restart a python kernel.  
                This is a huge debugging speedup since you only load data once, you do not have to reload it every time you change your code.<br>
                On the other hand, the debugger is primitive when compared to a full fledged IDE like PyCharm.<br>
                Also jupyter notebooks are used to prototype your solution.  Once everything works, you'll probably export the salient bits to packages and scripts to be used by other components, like a webservice or dashboard.<br>
                <!-- STOPPED WORKING 1/8/23-What's a dashboard? Its a way to aggregate and interactively display data in a user friendly way.  Here is an example <a href="https://kp-avocado.herokuapp.com">dashboard</a> (takes a bit to provision and load) created from <a href="https://realpython.com/python-dash/">this</a> excellent tutorial. -->
                  <br><br>
              
                <strong>References</strong><BR>
                <strong><a href="https://github.com/CNUClasses/DATA301/blob/master/content/lectures/week1/Pandas_Cheat_Sheet.pdf"> Pandas cheatsheet</a></strong><br>                   
                <strong><a href="https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf"> Anaconda cheatsheet</a></strong><br>
                <strong><a href="https://uoa-eresearch.github.io/eresearch-cookbook/recipe/2014/11/20/conda/">Virtual Environments</a></strong><br>
                <br>
                Anaconda and Windows - getting Jupyter Lab up and running in your virtual environment of choice (one of several ways)<BR>
                    <ol>
                        <li>Install anaconda</li>
                        <li>Run 'Anaconda Prompt'(use Windows search to find it)</li>
                        <li>Create virtual environment and activate it</li>
                        <li>start jupyter lab</li>
                    </ol>
                    A jupyter Lab browser window will appear
                <!--review 201 pandas, open, close, save (feather format?). <br>
                Statistics (nunique, describe, is_null(), isnull().sum()), info (dtype), indexes (reset_index()),  <br>
                Selection (slices, using boolean index, by column, by row), grouping (group_by)<br>
                sampling (if dataset is large get a subset, make sure subset has same mean and std as original)<br><br>
                New:<br>
                something new, joining (very similar to databases inner and outter join)<br>
                seaborn (fewer lines to plot)<br>
                seaborn scatterplots-use alpha value when plotting lots of points, this makes the plot show as a kind of heat map with densly populated areas being darker
                use interpolation to find hidden features, find correlated column, sort by it and interpolate missing values based on nearby rows
                plotly (interactive plots)<br><br>

                need extensive review of apply, map, and group_by on dataframes, see https://towardsdatascience.com/avoiding-apply-ing-yourself-in-pandas-a6ade4569b7f

                missing data- find it, average? closest (how?), predict with a model?<br>
                create artificial dataset with height weight, tshirt sizes.  Delete 10% of sizes, fit linear regression on remaining sizes, predict missing<br>
                show how median just fills in the average, show how linear regression is a little smarter<br>
                use gaussian distribution for weights verses sizes.<br> 

                Built in to sklearn<a href="https://scikit-learn.org/stable/modules/impute.html">Imputation of missing values</a> 
                and <a href="https://scikit-learn.org/stable/auto_examples/impute/plot_missing_values.html#sphx-glr-auto-examples-impute-plot-missing-values-py">Imputing missing values before building an estimator</a><br>-->

            </td>
            <td class="style_white ">
                <strong><a href="https://github.com/CNUClasses/DATA301_CODE/blob/master/week_1/1_JupyterUsage.ipynb">How to efficiently navigate a Jupyter Notebook</a></strong> Some keyboard shortcuts, "Magic" commands, how to run shell commands, getting API help, and an introduction to debugging in a Jupyter Notebook<br>
            </td>
        </tr>
     <tr>

        <td class="style_white "><em>2</em></td>
        <td class="style_white ">
            MLK Holiday <br>
            <!-- https://www.kaggle.com/code/ryanholbrook/mutual-information  A great first step is to construct a ranking with a feature utility metric, a function measuring associations between a feature and the target. Then you can choose a smaller set of the most useful features to develop initially and have more confidence that your time will be well spent. -->

            The metric we'll use is called "mutual information". Mutual information is a lot like correlation in that it measures a relationship between two quantities. The advantage of mutual information is that it can detect any kind of relationship, while correlation only detects linear relationships.
            <!--In Data Science you often start with a problem and work backwards, infilling the pieces you need, then its gathering data, stitching it together and implementing the components.
                Based on the music you like what other music can be reccomended to you?
                Drugs- clinical trials are expensive and there are a lot of drugs-  How do you select candidates for trial?   List of components, list of uses, effectiveness
                what you can see in data without predictions (melborne housing dataset, use to see where growth is happenning).  What else do you need?  Maybe prevaling interest rate feature.
                 who owns that plane?  track planes by id, track people (and employer) by destination, match one to another, once you have that you know where they are going and when, 
                 when did oligarchs know? - possible, track megayacht movements, look for deviations from the norm to safehavens, when this happened, they knew, same with planes
                 how can I predict recidivism for people convicted of a crime?  What can be done to prevent it?
                 What is the risk of civil war in a country? what to measure?  Political shift over time, hate speech (tweets, FB), weapon sales.  To that end I have a friend who is a complete hero, she was a professor of sociolgy here for years, she helps people become educated in gutemala, africa and nepal.  In 2007 she was in the kenyan bush during the ethnic conflicts, she said she used the machete index to determine if it was safe to go into town.  If the local hardware stores were out of machetes she stayed in the bush.
                 Can you tell if an establishment is being used for money laundering? Say your the IRS and you have the yearly tax returns for a small business that does nails, nail shops are pretty common compare to others in the same area. Maybe determine average return on expenses, compare. 
                 when am I going to die? what do you need for this, 
                Whats the best way to increase my chances of making friends?
                Whats the most effecient way to attack/starve an invading army? time series problem, Need sat images, Need ability to tally vehicles and troops, estimate fuel and food needs, track support staff.  Identify roads used.  What is the climate, what is the season.(winter, spring?).  Heavy equipment does not do well in mudd.  Overlay floodplain data, what if you block a river here? will supply routes flood.  What if you open a dam?  
                 Image stuff
                 your standing at Vernal falls in Yosemete and you want to take a picture with no one in it.  It's crowded - how do you do it?
                -->
                <br>
            <strong>References</strong><BR>
                
            <a href="https://www.kaggle.com/alexisbcook/inconsistent-data-entry"> Kaggle- text pre processing</a>Very good, especially the fuzzywuzzy module<br>              
            <a href="https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing">Text pre-processing</a> Good, although some of it (spell checking for instance) may not scale well<br>
            <a href=" https://realpython.com/inner-functions-what-are-they-good-for/#retaining-state-with-inner-functions-closures "> Real Python- Closures</a>  Closures are functions that have state, they are a good way to 
            genericize a function that you are applying to a DataFrame column in pandas.  See the 'Cleaning Strings' notebook below for an example.<br>
            <a href=" https://realpython.com/regex-python-part-2/#substitution-functions"> Real Python- Regular Expressions - re.sub</a><br> 
            <a href=" https://www.computerhope.com/unix/regex-quickref.htm">More regular expressions</a><br>
           <!-- <a href=" https://realpython.com/regex-python/ "> Regular Expressions- part 1</a><br> -->
             <!-- <a href=" https://realpython.com/regex-python-part-2/ "> Regular Expressions- part 2</a><br> -->
                             
        </td>
        <td class="style_white ">
            <strong><a href="https://github.com/CNUClasses/DATA301_CODE/blob/master/week_2/22_review_chapter_5.ipynb">Pandas Intro</a></strong> Chapter 5, McKinney<br>
            <strong><a href="https://github.com/CNUClasses/DATA301_CODE/blob/master/week_2/23_review_chapter_6.ipynb">Data Loading and Saving</a></strong> Chapter 6, McKinney<br>  
            <strong><a href="https://github.com/CNUClasses/DATA301_CODE/blob/master/week_2/24_cleaning_strings.ipynb">Cleaning strings</a></strong> Some introductory string cleaning suggestions demonstrated by normalizing user entries for 'Country'. Starts with standard transforms and finishes with task specific transforms using <a href="https://p
            ypi.org/project/pycountry/">pycountry</a>. (BTW check out the nifty tqdm progress meter, very useful for long running bits of code) <br>  
            

        </td>
    </tr>

       
        </table>
